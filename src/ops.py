"""
TF util operations.
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf


def keypoint_l1_loss(kp_gt, kp_pred, scale=1., name=None):
    """
    computes: \Sum_i [0.5 * vis[i] * |kp_gt[i] - kp_pred[i]|] / (|vis|)
    Inputs:
      kp_gt  : N x K x 3
      kp_pred: N x K x 2
    """
    with tf.name_scope(name, "keypoint_l1_loss", [kp_gt, kp_pred]):
        kp_gt = tf.reshape(kp_gt, (-1, 3))
        kp_pred = tf.reshape(kp_pred, (-1, 2))
        # visualibity, True/ False ==> 1.0/0.
        vis = tf.expand_dims(tf.cast(kp_gt[:, 2], tf.float32), 1)
        res = tf.losses.absolute_difference(kp_gt[:, :2], kp_pred, weights=vis)
        return res

def compute_3d_loss(params_pred, params_gt, has_gt3d):
    """
    Computes the l2 loss between 3D params pred and gt for those data that has_gt3d is True.
    Parameters to compute loss over:
    3Djoints: 14*3 = 42
    rotations:(24*9)= 216
    shape: 10
    total input: 226 (gt SMPL params) or 42 (just joints)

    Inputs:
      params_pred: N x {226, 42}
      params_gt: N x {226, 42}
      # has_gt3d: (N,) bool
      has_gt3d: N x 1 tf.float32 of {0., 1.}
    """
    with tf.name_scope("3d_loss", [params_pred, params_gt, has_gt3d]):
        weights = tf.expand_dims(tf.cast(has_gt3d, tf.float32), 1)
        res = tf.losses.mean_squared_error(
            params_gt, params_pred, weights=weights) * 0.5
        return res


def align_by_pelvis(joints):
    """
    Assumes joints is N x 14 x 3 in LSP order.
    Then hips are: [3, 2]
    Takes mid point of these points, then subtracts it.
    """
    with tf.name_scope("align_by_pelvis", [joints]):
        left_id = 3
        right_id = 2
        pelvis = (joints[:, left_id, :] + joints[:, right_id, :]) / 2.
        return joints - tf.expand_dims(pelvis, axis=1)

""" newly added for depth loss and depth rendering """
# cam: N x 3
# cam_trans: N x 3, i.e., [tx, ty, tz] 
def get_batched_cam_trans(cam, f = 5.0):
    #f = 5.0
    tz = tf.reshape(f / cam[:, 0], [-1, 1])
    # Bug is found here!!! change cam[:, 0:2] (i.e., s, tx) to cam[:, 1:3] (i.e., tx, ty)
    #cam_trans = tf.concat([cam[:, 0:2], tz], axis = 1) # [N, 3]
    cam_trans = tf.concat([cam[:, 1:3], tz], axis = 1) # [N, 3]
    return cam_trans

def get_proj_vert2d(verts, cams, f = 5.0,  img_size = 224):
      """
      inputs:
        * verts : N x 6890 x 3, where N is batch_size, and 6890 is the number of vertices generated by SMPL layer;
        * cams : N x 3, where 3 = S, tx, ty;
      outputs:
        * proj_vert2d: projected 2d points (x,y) in pixel, with size N x 6890 x 2
        *              proj_vert2d: x, y, i.e, x -> imgW, y -> imgH, so if you want to 
        *              get the index of (h_idx, w_idx), you have to change the order (x,y) to (y, x);
        * pred_depth : N x 6890
      """

      # Note: in batch_orth_proj_idrot():
      # u <-- S*(x + tx)
      # v <-- S*(y + ty)
      # verts : N x 6890 x 3
      #print ('[???] verts.shape = ', verts.shape)

      # step 1) : u <-- x + tx; v <-- y + ty;
      cam_trans = get_batched_cam_trans(cams, f) # N x 3
      cam_trans = tf.reshape(cam_trans, [-1, 1, 3]) # N x 1 X 3
      vert_shifted = verts + cam_trans # N x 6890 x 3
      # step 2) : multiply x and y with scale S;
      shape = tf.shape(vert_shifted[:,:,:2])
      batch_size = shape[0]
      num_vert = shape[1]
      # (N x 1) * (N x 6890 *2), with broadcast, so ==> N x 6890*2
      proj_vert2d = tf.reshape(
                      cams[:, 0], [-1, 1]) * tf.reshape(vert_shifted[:,:,0:2], 
                      [batch_size, -1]) # N x (6890*2)
      proj_vert2d = tf.reshape(proj_vert2d, shape) # N x 6890 x 2
        
      pred_depth = vert_shifted[:, :, 2] # N x 6890
      
      # undo scale [-1, 1] joints2d to [0, img_size - 1];
      # N x 6890 x 2
      proj_vert2d = tf.cast(((proj_vert2d + 1.0) * 0.5) * img_size, tf.int32) # now in pixel unit;
      return proj_vert2d, pred_depth, num_vert
      